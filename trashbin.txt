
resource "null_resource" "wait_for_aks" {
  depends_on = [azurerm_kubernetes_cluster.aks]

  provisioner "local-exec" {
    command = <<EOT
    for i in {1..30}; do
      kubectl --kubeconfig=kubeconfig.yaml get nodes && break
      echo "Waiting for AKS to be ready..."
      sleep 10
    done
    EOT
  }
}

# --------------------------------------------------
# ArgoCD Helm Release
# --------------------------------------------------
resource "helm_release" "argocd" {
  depends_on = [null_resource.wait_for_aks]

  name             = "argocd"
  repository       = "https://argoproj.github.io/argo-helm"
  chart            = "argo-cd"
  namespace        = "argocd"
  create_namespace = true

  set {
    name  = "server.service.type"
    value = "LoadBalancer"
  }
}

data "kubernetes_service" "argocd_server" {

  depends_on = [helm_release.argocd]

  metadata {
    name      = "argocd-server"
    namespace = "argocd"
  }
}

 
data "azurerm_kubernetes_cluster" "aks" {
  name                = azurerm_kubernetes_cluster.aks.name
  resource_group_name = azurerm_kubernetes_cluster.aks.resource_group_name
}

provider "kubernetes" {
  host                   = data.azurerm_kubernetes_cluster.aks.kube_config[0].host
  client_certificate     = base64decode(data.azurerm_kubernetes_cluster.aks.kube_config[0].client_certificate)
  client_key             = base64decode(data.azurerm_kubernetes_cluster.aks.kube_config[0].client_key)
  cluster_ca_certificate = base64decode(data.azurerm_kubernetes_cluster.aks.kube_config[0].cluster_ca_certificate)
}

provider "helm" {
  kubernetes {
    host                   = data.azurerm_kubernetes_cluster.aks.kube_config[0].host
    client_certificate     = base64decode(data.azurerm_kubernetes_cluster.aks.kube_config[0].client_certificate)
    client_key             = base64decode(data.azurerm_kubernetes_cluster.aks.kube_config[0].client_key)
    cluster_ca_certificate = base64decode(data.azurerm_kubernetes_cluster.aks.kube_config[0].cluster_ca_certificate)
  }
}

 

  subscription_id = "e588fe1d-fa2a-47c7-8954-6e57713bd778"

 
EW_SUBSCRIPTION_ID
 
  subscription_id = "NEW_SUBSCRIPTION_ID"
 
est US 2
 
centralus
 
azurerm_kubernetes_cluster.aks
 
# Kubernetes Provider (after AKS is created)
provider "kubernetes" {
  alias                  = "aks"
  host                   = azurerm_kubernetes_cluster.aks.kube_config[0].host
  client_certificate     = base64decode(azurerm_kubernetes_cluster.aks.kube_config[0].client_certificate)
  client_key             = base64decode(azurerm_kubernetes_cluster.aks.kube_config[0].client_key)
  cluster_ca_certificate = base64decode(azurerm_kubernetes_cluster.aks.kube_config[0].cluster_ca_certificate)

  # This forces Terraform to wait for the cluster
  depends_on = [azurerm_kubernetes_cluster.aks]
}

# Helm Provider (uses the same AKS provider)
provider "helm" {
  kubernetes {
    host                   = azurerm_kubernetes_cluster.aks.kube_config[0].host
    client_certificate     = base64decode(azurerm_kubernetes_cluster.aks.kube_config[0].client_certificate)
    client_key             = base64decode(azurerm_kubernetes_cluster.aks.kube_config[0].client_key)
    cluster_ca_certificate = base64decode(azurerm_kubernetes_cluster.aks.kube_config[0].cluster_ca_certificate)
  }

  depends_on = [azurerm_kubernetes_cluster.aks]
}


 

# Kubernetes Provider
provider "kubernetes" {
  host                   = azurerm_kubernetes_cluster.aks.kube_config[0].host
  client_certificate     = base64decode(azurerm_kubernetes_cluster.aks.kube_config[0].client_certificate)
  client_key             = base64decode(azurerm_kubernetes_cluster.aks.kube_config[0].client_key)
  cluster_ca_certificate = base64decode(azurerm_kubernetes_cluster.aks.kube_config[0].cluster_ca_certificate)

}

# Helm Provider
provider "helm" {
  kubernetes {
    host                   = azurerm_kubernetes_cluster.aks.kube_config[0].host
    client_certificate     = base64decode(azurerm_kubernetes_cluster.aks.kube_config[0].client_certificate)
    client_key             = base64decode(azurerm_kubernetes_cluster.aks.kube_config[0].client_key)
    cluster_ca_certificate = base64decode(azurerm_kubernetes_cluster.aks.kube_config[0].cluster_ca_certificate)
  }
}
 
# Kubernetes Provider
provider "kubernetes" {
  host                   = azurerm_kubernetes_cluster.aks.kube_config[0].host
  client_certificate     = base64decode(azurerm_kubernetes_cluster.aks.kube_config[0].client_certificate)
  client_key             = base64decode(azurerm_kubernetes_cluster.aks.kube_config[0].client_key)
  cluster_ca_certificate = base64decode(azurerm_kubernetes_cluster.aks.kube_config[0].cluster_ca_certificate)

}
 
  load_config_file       = false
 
# Fetch kubeconfig from AKS
data "azurerm_kubernetes_cluster" "aks" {
  name                = azurerm_kubernetes_cluster.aks.name
  resource_group_name = azurerm_resource_group.rg.name

  depends_on = [azurerm_kubernetes_cluster.aks] 
}

 
# Kubernetes Provider
provider "kubernetes" {
  host                   = azurerm_kubernetes_cluster.aks.kube_config[0].host
  client_certificate     = base64decode(data.azurerm_kubernetes_cluster.aks.kube_config[0].client_certificate)
  client_key             = base64decode(data.azurerm_kubernetes_cluster.aks.kube_config[0].client_key)
  cluster_ca_certificate = base64decode(data.azurerm_kubernetes_cluster.aks.kube_config[0].cluster_ca_certificate)
}

# Helm Provider (uses same kubeconfig)
provider "helm" {
  kubernetes {
    host                   = azurerm_kubernetes_cluster.aks.kube_config[0].host
    client_certificate     = base64decode(data.azurerm_kubernetes_cluster.aks.kube_config[0].client_certificate)
    client_key             = base64decode(data.azurerm_kubernetes_cluster.aks.kube_config[0].client_key)
    cluster_ca_certificate = base64decode(data.azurerm_kubernetes_cluster.aks.kube_config[0].cluster_ca_certificate)
  }
}
 
data.azurerm_kubernetes_cluster.aks.kube_config[0].host
 
 host                   = 
 
data.azurerm_kubernetes_cluster.aks.kube_config[0].host
 
# Kubernetes Provider (connects Terraform to your AKS cluster)
provider "kubernetes" {
  host                   = azurerm_kubernetes_cluster.aks.kube_config[0].host
  client_certificate     = base64decode(azurerm_kubernetes_cluster.aks.kube_config[0].client_certificate)
  client_key             = base64decode(azurerm_kubernetes_cluster.aks.kube_config[0].client_key)
  cluster_ca_certificate = base64decode(azurerm_kubernetes_cluster.aks.kube_config[0].cluster_ca_certificate)
}

# Helm Provider (connects Terraform Helm charts to AKS)
provider "helm" {
  kubernetes {
    host                   = azurerm_kubernetes_cluster.aks.kube_config[0].host
    client_certificate     = base64decode(azurerm_kubernetes_cluster.aks.kube_config[0].client_certificate)
    client_key             = base64decode(azurerm_kubernetes_cluster.aks.kube_config[0].client_key)
    cluster_ca_certificate = base64decode(azurerm_kubernetes_cluster.aks.kube_config[0].cluster_ca_certificate)
  }
}

 
netes_cluster" "aks" {
  name                = azurerm_kubernetes_cluster.aks.name
  resource_group_name = azurerm_resource_group.rg.name
}


 
# AKS Cluster
resource "azurerm_kubernetes_cluster" "aks" {
  name                = var.cluster_name
  location            = azurerm_resource_group.rg.location
  resource_group_name = azurerm_resource_group.rg.name
  dns_prefix          = "${var.cluster_name}-dns"

  default_node_pool {
    name       = "systempool"
    node_count = var.node_count
    vm_size    = "Standard_D2s_v3"
  }

  identity {
    type = "SystemAssigned"
  }


}

data "azurerm_kuber
 
uaenorth
 
output "argocd_loadbalancer_ip" {
  description = "Public IP of the Argo CD LoadBalancer service"
  value       = data.kubernetes_service.argocd_server
}

 
output "argocd_loadbalancer_ip" {
  description = "Public IP of the Argo CD LoadBalancer service"
  value       = data.kubernetes_service.argocd_server.status[0].load_balancer[0].ingress[0].ip
}

 

output "argocd_server_url" {
  description = "The external URL to access the Argo CD server"
  value       = "https://${helm_release.argocd.name}.argocd.${azurerm_kubernetes_cluster.aks.name}.azurecontainer.io"
}

 
resource "helm_release" "argocd" {
  depends_on = [azurerm_kubernetes_cluster.aks]

  name       = "argocd"
  repository = "https://argoproj.github.io/argo-helm"
  chart      = "argo-cd"
  namespace  = "argocd"
  create_namespace = true

  set {
    name  = "server.service.type"
    value = "LoadBalancer"
  }
}

 
terraform {
  required_version = ">=0.12"

  required_providers {
    azapi = {
      source  = "azure/azapi"
      version = "~>1.5"
    }
    azurerm = {
      source  = "hashicorp/azurerm"
      version = "~>3.0"
    }
    random = {
      source  = "hashicorp/random"
      version = "~>3.0"
    }

    helm = {
      source  = "hashicorp/helm"
      version = "~> 2.13"
    }

    kubernetes = {
      source  = "hashicorp/kubernetes"
      version = "~> 2.29"
    }
    
  }
}


provider "azurerm" {
  features {}
}
 
resource "helm_release" "argocd" {
  name             = "argocd"
  repository       = "https://argoproj.github.io/argo-helm"
  chart            = "argo-cd"
  namespace        = "argocd"
  create_namespace = true
  version          = "7.3.7" # Example version

}
 
  values = [
    file("values/argocd-values.yaml")
  ]
 
    } 
}
 
     terraform {
      required_providers {
        helm = { source = "hashicorp/helm", version = "~> 2.13" }
        kubernetes = { source = "hashicorp/kubernetes", version = "~> 2.29" }
      }
 
tandard_B1s
 
Standard_B4ms
 
Standard_DS2_v2
 
Name of the AKS cluster
 
  tags = {
    Environment = "Dev"
  }
 
sonarqube
 
https://raw.githubusercontent.com/<your-repo>/install-sonarqube.sh"
 

resource "azurerm_virtual_machine_extension" "sonarqube_install" {
  name                 = "install-sonarqube"
  virtual_machine_id   = azurerm_linux_virtual_machine.my_terraform_vm.id
  publisher            = "Microsoft.Azure.Extensions"
  type                 = "CustomScript"
  type_handler_version = "2.1"

  settings = jsonencode({
    fileUris = [
      
    ]
    commandToExecute = <<-EOT
      bash -c 'set -euo pipefail;
      # Run upstream installer if present
      if [ -f ./sonarqube.sh ]; then bash ./sonarqube.sh || true; fi;
      # Ensure non-root user exists and owns SonarQube dirs
      id -u sonarqube >/dev/null 2>&1 || useradd --system --home-dir /opt/sonarqube --shell /bin/bash sonarqube;
      mkdir -p /opt/sonarqube/{logs,data,temp,extensions};
      chown -R sonarqube:sonarqube /opt/sonarqube;
      # Force sonar.sh to drop privileges
      if [ -f /opt/sonarqube/bin/linux-x86-64/sonar.sh ]; then sed -i "s/^#\\?RUN_AS_USER=.*/RUN_AS_USER=sonarqube/" /opt/sonarqube/bin/linux-x86-64/sonar.sh; fi;
      # Ensure systemd runs as sonarqube with sane limits
      if [ -f /etc/systemd/system/sonar.service ]; then
        if ! grep -q "^User=sonarqube" /etc/systemd/system/sonar.service; then
          awk "BEGIN{a=0}{print}/^\\[Service\\]$/{if(a==0){print \\"User=sonarqube\\\\nGroup=sonarqube\\\\nLimitNOFILE=65536\\\\nLimitNPROC=4096\\"; a=1}}" /etc/systemd/system/sonar.service > /etc/systemd/system/sonar.service.new;
          mv /etc/systemd/system/sonar.service.new /etc/systemd/system/sonar.service;
        fi;
      fi;
      # Kernel and security limits
      printf "sonarqube - nofile 65536\\nsonarqube - nproc 4096\\n" > /etc/security/limits.d/99-sonarqube.conf;
      sysctl -w vm.max_map_count=262144;
      grep -q "vm.max_map_count" /etc/sysctl.conf || echo "vm.max_map_count=262144" >> /etc/sysctl.conf;
      # Bind web to all interfaces on 9000
      if [ -f /opt/sonarqube/conf/sonar.properties ]; then
        sed -i "s/^#\\?sonar.web.host=.*/sonar.web.host=0.0.0.0/" /opt/sonarqube/conf/sonar.properties;
        sed -i "s/^#\\?sonar.web.port=.*/sonar.web.port=9000/" /opt/sonarqube/conf/sonar.properties;
      fi;
      # Restart service
      systemctl daemon-reload;
      systemctl enable --now sonar || true'
    EOT
  })
}

 
resource "azurerm_virtual_machine_extension" "sonarqube_install" {
  name                 = "install-sonarqube"
  virtual_machine_id   = azurerm_linux_virtual_machine.my_terraform_vm.id
  publisher            = "Microsoft.Azure.Extensions"
  type                 = "CustomScript"
  type_handler_version = "2.1"

  settings = jsonencode({
    fileUris = [
      "https://raw.githubusercontent.com/Senuthmi/microservices-demo/main/scripts/sonarqube.sh"
    ]
    commandToExecute = <<-EOT
      bash -c 'set -euo pipefail;
      # Run upstream installer if present
      if [ -f ./sonarqube.sh ]; then bash ./sonarqube.sh || true; fi;
      # Ensure non-root user exists and owns SonarQube dirs
      id -u sonarqube >/dev/null 2>&1 || useradd --system --home-dir /opt/sonarqube --shell /bin/bash sonarqube;
      mkdir -p /opt/sonarqube/{logs,data,temp,extensions};
      chown -R sonarqube:sonarqube /opt/sonarqube;
      # Force sonar.sh to drop privileges
      if [ -f /opt/sonarqube/bin/linux-x86-64/sonar.sh ]; then sed -i "s/^#\\?RUN_AS_USER=.*/RUN_AS_USER=sonarqube/" /opt/sonarqube/bin/linux-x86-64/sonar.sh; fi;
      # Ensure systemd runs as sonarqube with sane limits
      if [ -f /etc/systemd/system/sonar.service ]; then
        if ! grep -q "^User=sonarqube" /etc/systemd/system/sonar.service; then
          awk "BEGIN{a=0}{print}/^\\[Service\\]$/{if(a==0){print \\"User=sonarqube\\\\nGroup=sonarqube\\\\nLimitNOFILE=65536\\\\nLimitNPROC=4096\\"; a=1}}" /etc/systemd/system/sonar.service > /etc/systemd/system/sonar.service.new;
          mv /etc/systemd/system/sonar.service.new /etc/systemd/system/sonar.service;
        fi;
      fi;
      # Kernel and security limits
      printf "sonarqube - nofile 65536\\nsonarqube - nproc 4096\\n" > /etc/security/limits.d/99-sonarqube.conf;
      sysctl -w vm.max_map_count=262144;
      grep -q "vm.max_map_count" /etc/sysctl.conf || echo "vm.max_map_count=262144" >> /etc/sysctl.conf;
      # Bind web to all interfaces on 9000
      if [ -f /opt/sonarqube/conf/sonar.properties ]; then
        sed -i "s/^#\\?sonar.web.host=.*/sonar.web.host=0.0.0.0/" /opt/sonarqube/conf/sonar.properties;
        sed -i "s/^#\\?sonar.web.port=.*/sonar.web.port=9000/" /opt/sonarqube/conf/sonar.properties;
      fi;
      # Restart service
      systemctl daemon-reload;
      systemctl enable --now sonar || true'
    EOT
  })
}
 
resource "azurerm_virtual_machine_extension" "sonarqube_install" {
  name                 = "install-sonarqube"
  virtual_machine_id   = azurerm_linux_virtual_machine.my_terraform_vm.id
  publisher            = "Microsoft.Azure.Extensions"
  type                 = "CustomScript"
  type_handler_version = "2.1"

  settings = jsonencode({
    fileUris = [
      "https://raw.githubusercontent.com/Senuthmi/microservices-demo/main/scripts/sonarqube.sh"
    ]
    commandToExecute = <<-EOT
      bash -c 'set -euo pipefail;
      # Run upstream installer if present
      if [ -f ./sonarqube.sh ]; then bash ./sonarqube.sh || true; fi;
      # Ensure non-root user exists and owns SonarQube dirs
      id -u sonarqube >/dev/null 2>&1 || useradd --system --home-dir /opt/sonarqube --shell /bin/bash sonarqube;
      mkdir -p /opt/sonarqube/{logs,data,temp,extensions};
      chown -R sonarqube:sonarqube /opt/sonarqube;
      # Force sonar.sh to drop privileges
      if [ -f /opt/sonarqube/bin/linux-x86-64/sonar.sh ]; then sed -i "s/^#\\?RUN_AS_USER=.*/RUN_AS_USER=sonarqube/" /opt/sonarqube/bin/linux-x86-64/sonar.sh; fi;
      # Ensure systemd runs as sonarqube with sane limits
      if [ -f /etc/systemd/system/sonar.service ]; then
        if ! grep -q "^User=sonarqube" /etc/systemd/system/sonar.service; then
          awk "BEGIN{a=0}{print}/^\\[Service\\]$/{if(a==0){print \\"User=sonarqube\\\\nGroup=sonarqube\\\\nLimitNOFILE=65536\\\\nLimitNPROC=4096\\"; a=1}}" /etc/systemd/system/sonar.service > /etc/systemd/system/sonar.service.new;
          mv /etc/systemd/system/sonar.service.new /etc/systemd/system/sonar.service;
        fi;
      fi;
      # Kernel and security limits
      printf "sonarqube - nofile 65536\\nsonarqube - nproc 4096\\n" > /etc/security/limits.d/99-sonarqube.conf;
      sysctl -w vm.max_map_count=262144;
      grep -q "vm.max_map_count" /etc/sysctl.conf || echo "vm.max_map_count=262144" >> /etc/sysctl.conf;
      # Bind web to all interfaces on 9000
      if [ -f /opt/sonarqube/conf/sonar.properties ]; then
        sed -i "s/^#\\?sonar.web.host=.*/sonar.web.host=0.0.0.0/" /opt/sonarqube/conf/sonar.properties;
        sed -i "s/^#\\?sonar.web.port=.*/sonar.web.port=9000/" /opt/sonarqube/conf/sonar.properties;
      fi;
      # Restart service
      systemctl daemon-reload;
      systemctl enable --now sonar || true'
    EOT
  })
}



 
resource "azurerm_virtual_machine_extension" "sonarqube_install" {
  name                 = "install-sonarqube"
  virtual_machine_id   = azurerm_linux_virtual_machine.my_terraform_vm.id
  publisher            = "Microsoft.Azure.Extensions"
  type                 = "CustomScript"
  type_handler_version = "2.1"

  settings = jsonencode({
    fileUris = [
      "https://raw.githubusercontent.com/Senuthmi/microservices-demo/main/scripts/sonarqube.sh"
    ]
    commandToExecute = "bash -c 'set -euo pipefail; \
      # Run upstream installer if present\n \
      if [ -f ./sonarqube.sh ]; then bash ./sonarqube.sh || true; fi; \
      # Ensure non-root user exists and owns SonarQube dirs\n \
      id -u sonarqube >/dev/null 2>&1 || useradd --system --home-dir /opt/sonarqube --shell /bin/bash sonarqube; \
      mkdir -p /opt/sonarqube/{logs,data,temp,extensions}; \
      chown -R sonarqube:sonarqube /opt/sonarqube; \
      # Force sonar.sh to drop privileges\n \
      if [ -f /opt/sonarqube/bin/linux-x86-64/sonar.sh ]; then sed -i \"s/^#\\?RUN_AS_USER=.*/RUN_AS_USER=sonarqube/\" /opt/sonarqube/bin/linux-x86-64/sonar.sh; fi; \
      # Ensure systemd runs as sonarqube with sane limits\n \
      if [ -f /etc/systemd/system/sonar.service ]; then \
        if ! grep -q '^User=sonarqube' /etc/systemd/system/sonar.service; then \
          awk 'BEGIN{a=0}{print}/^\\[Service\\]$/{if(a==0){print "User=sonarqube\\nGroup=sonarqube\\nLimitNOFILE=65536\\nLimitNPROC=4096"; a=1}}' /etc/systemd/system/sonar.service > /etc/systemd/system/sonar.service.new; \
          mv /etc/systemd/system/sonar.service.new /etc/systemd/system/sonar.service; \
        fi; \
      fi; \
      # Kernel and security limits\n \
      printf \"sonarqube - nofile 65536\\nsonarqube - nproc 4096\\n\" > /etc/security/limits.d/99-sonarqube.conf; \
      sysctl -w vm.max_map_count=262144; \
      grep -q \"vm.max_map_count\" /etc/sysctl.conf || echo \"vm.max_map_count=262144\" >> /etc/sysctl.conf; \
      # Bind web to all interfaces on 9000\n \
      if [ -f /opt/sonarqube/conf/sonar.properties ]; then \
        sed -i 's/^#\\?sonar.web.host=.*/sonar.web.host=0.0.0.0/' /opt/sonarqube/conf/sonar.properties; \
        sed -i 's/^#\\?sonar.web.port=.*/sonar.web.port=9000/' /opt/sonarqube/conf/sonar.properties; \
      fi; \
      # Restart service\n \
      systemctl daemon-reload; \
      systemctl enable --now sonar || true'"
  })
}
 
azapi_resource_action.ssh_public_key_gen.output.publicKey
 
<your-github-username>
 
Standard_DS1_v2
 
# We strongly recommend using the required_providers block to set the
# Azure Provider source and version being used
terraform {
  required_providers {
    azurerm = {
      source  = "hashicorp/azurerm"
      version = "=4.1.0"
    }
  }
}

provider "azurerm" {
  features {}

  # Explicitly tell Terraform which subscription to use
  subscription_id = "b079145a-6257-4feb-affc-47d6fb7d4824"
}
 
# Storage account variables
variable "storage_account_name" {
  description = "Name of the Storage Account"
  type        = string
  default     = "mystorageacct123"
}
 
# Create a virtual network within the resource group
resource "azurerm_virtual_network" "vnet" {
  name                = "example-network"
  resource_group_name = azurerm_resource_group.rg.name
  location            = azurerm_resource_group.rg.location
  address_space       = ["10.0.0.0/16"]
}

 
# Configure the Microsoft Azure Provider
provider "azurerm" {
  resource_provider_registrations = "none" # This is only required when the User, Service Principal, or Identity running Terraform lacks the permissions to register Azure Resource Providers.
  features {}
}
 
West Europe
 
my-resource-group
 
example-resources
 
example
 
